{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# IML and xAI with SHAP\n",
        "\n",
        "In this tutorial we will try to obtain explanations for the black-box/non-interpretable models using **[shap](https://shap.readthedocs.io/en/latest/) (SHapley Additive exPlanations)**. We will cover the basics of shap usage with the examples on tabular, image and text data."
      ],
      "metadata": {
        "id": "dSxUHnuPpbo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tabular data\n",
        "\n",
        "For the tabular data example we will apply [XGBoost](https://xgboost.readthedocs.io/en/stable/python/index.html) on [California Housing Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) to obtain the predictions of house prices. The explanations on how the prices of houses in particulare blocks are obtained are provided with the help of SHAP."
      ],
      "metadata": {
        "id": "MBiKg1FksLWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install shap\n",
        "!pip install shap"
      ],
      "metadata": {
        "id": "xd5aER2jtJmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import shap\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "xbmt1PgBsKyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pJN9tenpTY2"
      },
      "outputs": [],
      "source": [
        "# obtain the dataset for examination\n",
        "# the dataframe is a standard one provided by scikit-learn\n",
        "california_housing = fetch_california_housing(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print out the dataset description using the class descriptor\n",
        "print(california_housing.DESCR)"
      ],
      "metadata": {
        "id": "AICPnbKtttaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# examine the dataset\n",
        "california_housing.frame.head()"
      ],
      "metadata": {
        "id": "93L-gxOXuAyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look into the histograms of features\n",
        "california_housing.frame.hist(figsize=(12, 10), bins=30, edgecolor=\"black\")\n",
        "plt.subplots_adjust(hspace=0.7, wspace=0.4)"
      ],
      "metadata": {
        "id": "W4gAwnI0uVYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the sake of the tutorial we will not perform any manipulations with data, although there should be some correlated variables, as the purpose is to look into explainability of the model."
      ],
      "metadata": {
        "id": "u1Vd3iwDu54Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the separated features and targets\n",
        "X_tab, y_tab = fetch_california_housing(return_X_y=True, as_frame=True)"
      ],
      "metadata": {
        "id": "TMeyumpHuo9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is not necessary to perform the train_test_split to obtain shaply values. We just need a dataset and a model, that has been fitted to this dataset."
      ],
      "metadata": {
        "id": "DSNnFRykIfuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create XGBoost instance, parameters have been taken arbitraly to provide rather good performance\n",
        "xgb = xgb.XGBRegressor(colsample_bytree = 1, eta=0.3, learning_rate = 0.1, max_depth = 5, alpha = 10, n_estimators = 2000)\n",
        "\n",
        "# fit model to data\n",
        "xgb.fit(X_tab, y_tab)\n",
        "\n",
        "# make predictions on the same set to assess train performance\n",
        "predictions = xgb.predict(X_tab)\n",
        "\n",
        "print(f'Train MSE: {mean_squared_error(y_tab, predictions):.4f}')\n",
        "print(f'Train R-Squared: {r2_score(y_tab, predictions):.4f}')"
      ],
      "metadata": {
        "id": "R1K3tjySvWEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here comes the most interesting part: generation of shapley values to explain the predictions. `shap` library contains many types of [explainers](https://shap.readthedocs.io/en/latest/api.html#explainers) for different kind of models, but we will focus on the following three:\n",
        "- [Explainer](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html#shap.Explainer) (a universal method to explain any ML model)\n",
        "- [TreeExplainer](https://shap.readthedocs.io/en/latest/generated/shap.TreeExplainer.html) (to explain the output of ensemble tree models)\n",
        "- [DeepExplainer](https://shap.readthedocs.io/en/latest/generated/shap.DeepExplainer.html) (to approximate SHAP values for deep learning models)\n"
      ],
      "metadata": {
        "id": "yTkD9oDuU5co"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictibly, we will use TreeExplainer to obtain explanations for the XGBoost instance we've created above."
      ],
      "metadata": {
        "id": "L0N4AU0gYVCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the explainer with the model instance being the parameter\n",
        "explainer_tab = shap.TreeExplainer(xgb)\n",
        "\n",
        "# calculate approximate shapley values using our dataset of features\n",
        "shap_values_tab = explainer_tab(X_tab)"
      ],
      "metadata": {
        "id": "8bISPDSBvW5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can we explain the shapley value: **Given the current set of feature values**, the contribution of a feature value to the difference between the actual prediction and the mean prediction is the estimated Shapley value.\n",
        "\n",
        "The Shapley value is **NOT** the difference in prediction when we would remove the feature from the model.\n",
        "\n",
        "The Shapley value returns a simple value per feature, but no prediction model like. It cannot be used to make statements about changes in prediction for changes in the input.\n"
      ],
      "metadata": {
        "id": "PlRokvWrZRay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the explanation for a particular observation\n",
        "shap.plots.waterfall(shap_values_tab[0])"
      ],
      "metadata": {
        "id": "2RiujpwMw1kD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the necessary javascript libraries for interactive plots (in Google Colab should be used in every cell)\n",
        "shap.plots.initjs()\n",
        "\n",
        "# visualize the first prediction's explanation with a force plot\n",
        "shap.plots.force(shap_values_tab[0])"
      ],
      "metadata": {
        "id": "7qC3JLU9549R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the necessary javascript libraries for interactive plots\n",
        "shap.plots.initjs()\n",
        "\n",
        "# visualize force plot for many observations\n",
        "shap.plots.force(shap_values_tab[:50])"
      ],
      "metadata": {
        "id": "YVtNuESu55_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average shapley values could be used as a global method to understand which features have the highest impact on the target variable. Note: the mean of *absolute* values is plotted."
      ],
      "metadata": {
        "id": "SaCeNbY3bPd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# average shap values\n",
        "shap.plots.bar(shap_values_tab)"
      ],
      "metadata": {
        "id": "DLNDk34x8XbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Images"
      ],
      "metadata": {
        "id": "C38qDOyN97L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the image explanation example we will use the same model as in Tutorial 2 with a small change: for ReLU layers the `inplace=False` is sey so that outputs of the ReLU were not overwriting the output of the previous action."
      ],
      "metadata": {
        "id": "FAcmCNJ9bsFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "m6zkRkGVeiPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FashionNet, self).__init__()\n",
        "\n",
        "        self.convolutional_layer = nn.Sequential(\n",
        "\n",
        "            # convolutional layer 1\n",
        "            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, padding=0),\n",
        "            nn.BatchNorm2d(10),\n",
        "            nn.ReLU(inplace=False), # here is the change\n",
        "\n",
        "            # max pooling layer 1\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # convolutional layer 2\n",
        "            nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, padding=0),\n",
        "            nn.BatchNorm2d(20),\n",
        "            nn.ReLU(inplace=False), # here is the change\n",
        "\n",
        "            # max pooling layer 2\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.linear_layer = nn.Sequential(\n",
        "            nn.Linear(in_features=20*4*4, out_features=80),\n",
        "            nn.ReLU(inplace=False), # here is the change\n",
        "            nn.Linear(in_features=80, out_features=10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, verbose=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          x of shape (batch_size, 1, 28, 28): Input images.\n",
        "          verbose: True if you want to print the shapes of the intermediate variables.\n",
        "\n",
        "        Returns:\n",
        "          y of shape (batch_size, 10): Outputs of the network.\n",
        "        \"\"\"\n",
        "        x = self.convolutional_layer(x)\n",
        "        x = x.view(-1, 20*4*4)\n",
        "        x = self.linear_layer(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "3P3A2NBieSfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Transform to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
        "])\n",
        "\n",
        "# download the dataset\n",
        "testset = torchvision.datasets.FashionMNIST(root='', train=False, download=True, transform=transform)\n",
        "\n",
        "# define the labels of the images\n",
        "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
        "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# specify the batch size for training and test\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
      ],
      "metadata": {
        "id": "adafXeN4-WYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the pre-saved checkpoint, the file name will be 'fashion_net.pth'\n",
        "!gdown 1V1QQ2qSnvmmsn4cGI_orzCepmOeyUO-5"
      ],
      "metadata": {
        "id": "so1VxfN9tkn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize our network\n",
        "model_image = FashionNet()\n",
        "\n",
        "# load trained models\n",
        "model_image.load_state_dict(torch.load('fashion_net.pth', map_location=torch.device('cpu')))"
      ],
      "metadata": {
        "id": "Mr3JG9Wke5Hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a loader with a batch of images\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=True)\n",
        "images, true_labels = next(iter(test_loader))\n",
        "\n",
        "# train images will be used to calculate the approximate shapley values\n",
        "train_images = images[:120]\n",
        "\n",
        "# images to assess shapley values\n",
        "# make sure that the sum of train and test images are less than the batch_size\n",
        "test_images = images[120:125]\n",
        "\n",
        "# initialize the DeepExplainer with the model instance and images for training being the parameters\n",
        "explainer_img = shap.DeepExplainer(model_image, train_images)\n",
        "\n",
        "# calculate approximate shapley values using our test dataset\n",
        "shap_values_img = explainer_img.shap_values(test_images)"
      ],
      "metadata": {
        "id": "kgHQlgLy8rOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create array for vizualizations\n",
        "shap_img_numpy = [np.swapaxes(np.swapaxes(s, 1, -1), 1, 2) for s in shap_values_img]\n",
        "test_img_numpy = np.swapaxes(np.swapaxes(test_images.numpy(), 1, -1), 1, 2)\n",
        "\n",
        "# create labels for vizualizations\n",
        "tl = [classes[idx] for idx in true_labels[120:125].numpy()]\n",
        "l = [classes[:] for _ in range(5)]\n",
        "\n",
        "# vizualize\n",
        "shap.image_plot(shap_img_numpy, -test_img_numpy, labels=np.array(l), true_labels=tl)"
      ],
      "metadata": {
        "id": "Cwm57Wwr984J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see how each pixel contributes to the determination wheather the picture belongs to a particcular class. Using the same library it is possible to obtain explanations for particular layers of NN and partition the picture in some other manner."
      ],
      "metadata": {
        "id": "Bqgc8ANXfh4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text"
      ],
      "metadata": {
        "id": "EhMWK9CHDm7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the text data we will see how particular words contribute to the classification of the text sequence. We will use a pre-trained transformer classification model from [hugginface](https://huggingface.co/nateraw/bert-base-uncased-emotion) and the [emotions dataset](https://huggingface.co/datasets/SetFit/emotion/)"
      ],
      "metadata": {
        "id": "RwVw_Vw4gGZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers"
      ],
      "metadata": {
        "id": "6o5477B4DzRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import the dependencies\n",
        "import datasets\n",
        "import scipy as sp\n",
        "import transformers"
      ],
      "metadata": {
        "id": "fI96UsZIDb8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the emotion dataset\n",
        "dataset_txt = datasets.load_dataset(\"emotion\", split=\"train\")\n",
        "data_txt = pd.DataFrame({\"text\": dataset_txt[\"text\"], \"emotion\": dataset_txt[\"label\"]})"
      ],
      "metadata": {
        "id": "Dlz5Q-aaDwSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model and tokenizer\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"nateraw/bert-base-uncased-emotion\", use_fast=True)\n",
        "model_txt = transformers.AutoModelForSequenceClassification.from_pretrained(\"nateraw/bert-base-uncased-emotion\")\n",
        "\n",
        "# extract labels\n",
        "labels = sorted(model_txt.config.label2id, key=model_txt.config.label2id.get)\n",
        "\n",
        "# send model to cpu\n",
        "model_txt.to('cpu')\n",
        "\n",
        "print(f'Emotions fror classification: {labels}')"
      ],
      "metadata": {
        "id": "-9ST13jpENh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this defines a that takes a list of strings and outputs scores for each class\n",
        "def f(texts):\n",
        "    # create a tensor from the list of sequences and send it to cpu\n",
        "    tv = torch.tensor(\n",
        "        [\n",
        "            tokenizer.encode(text, padding=\"max_length\", max_length=128, truncation=True)\n",
        "            for text in texts\n",
        "        ]\n",
        "    ).cpu()\n",
        "    # create attention mask and send it to cpu\n",
        "    attention_mask = (tv != 0).type(torch.int64).cpu()\n",
        "\n",
        "    # calculate model output\n",
        "    outputs = model_txt(tv, attention_mask=attention_mask)[0].detach().cpu().numpy()\n",
        "\n",
        "    # calculate the scores for each class\n",
        "    scores = (np.exp(outputs).T / np.exp(outputs).sum(-1)).T\n",
        "\n",
        "    # calculate the probabilities that the sequences belongs to the class\n",
        "    val = sp.special.logit(scores)\n",
        "\n",
        "    return val"
      ],
      "metadata": {
        "id": "vwGWx0RghArT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "method = \"transformers tokenizer\"\n",
        "\n",
        "# build an explainer by passing a transformers tokenizer\n",
        "if method == \"transformers tokenizer\":\n",
        "    explainer_txt = shap.Explainer(f, tokenizer, output_names=labels)\n",
        "\n",
        "# build an explainer by explicitly creating a masker\n",
        "elif method == \"default masker\":\n",
        "    masker = shap.maskers.Text(r\"\\W\")  # this will create a basic whitespace tokenizer\n",
        "    explainer_txt = shap.Explainer(f, masker, output_names=labels)"
      ],
      "metadata": {
        "id": "XFPCGYhhEOUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate shapley values for the test data\n",
        "shap_values_txt = explainer_txt(data_txt[\"text\"][:3])"
      ],
      "metadata": {
        "id": "49YIncrZER9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize\n",
        "shap.plots.text(shap_values_txt)"
      ],
      "metadata": {
        "id": "W3PvpZXSETul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using shap it is possible to see how each particular word contributes to the identification of class"
      ],
      "metadata": {
        "id": "m16pcYB1jCUg"
      }
    }
  ]
}